{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "amazing-convention",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-unknown",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Linear Regression\n",
    "  \n",
    "class LinearRegression() :\n",
    "      \n",
    "    def __init__( self, learning_rate, iterations ) :\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iterations = iterations\n",
    "          \n",
    "    # Function for model training\n",
    "    def fit(self, X, Y) :\n",
    "          \n",
    "        # no_of_training_examples, no_of_features\n",
    "          \n",
    "        self.m, self.n = X.shape\n",
    "          \n",
    "        # weight initialization\n",
    "          \n",
    "        self.W = np.zeros( self.n )\n",
    "        self.b = 0\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "          \n",
    "        # gradient descent learning\n",
    "                  \n",
    "        for i in range( self.iterations ) :\n",
    "            self.update_weights()\n",
    "        return self\n",
    "      \n",
    "    # Helper function to update weights in gradient descent\n",
    "      \n",
    "    def update_weights( self ) :\n",
    "             \n",
    "        Y_pred = self.predict( self.X )\n",
    "        # calculate gradients  #-2xi+yi-wtxi\n",
    "        dW = - ( 2 * ( self.X.T ).dot( self.Y - Y_pred )  ) / self.m\n",
    "        db = - 2 * np.sum( self.Y - Y_pred ) / self.m \n",
    "        \n",
    "        # update weights\n",
    "        self.W = self.W - self.learning_rate * dW\n",
    "        self.b = self.b - self.learning_rate * db\n",
    "          \n",
    "        return self\n",
    "      \n",
    "    # Hypothetical function  h( x ) \n",
    "      \n",
    "    def predict( self, X ) :\n",
    "        return X.dot( self.W ) + self.b\n",
    "     \n",
    "  \n",
    "# driver code\n",
    "  \n",
    "def main() :\n",
    "      \n",
    "    # Importing dataset\n",
    "      \n",
    "    df = pd.read_csv( \"salary_data.csv\" )\n",
    "  \n",
    "    X = df.iloc[:,:-1].values\n",
    "  \n",
    "    Y = df.iloc[:,1].values\n",
    "      \n",
    "    # Splitting dataset into train and test set\n",
    "  \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split( \n",
    "      X, Y, test_size = 1/3, random_state = 0 )\n",
    "      \n",
    "    # Model training\n",
    "      \n",
    "    model = LinearRegression( iterations = 1000, learning_rate = 0.01 )\n",
    "  \n",
    "    model.fit( X_train, Y_train )\n",
    "      \n",
    "    # Prediction on test set\n",
    "  \n",
    "    Y_pred = model.predict( X_test )\n",
    "      \n",
    "    print( \"Predicted values \", np.round( Y_pred[:3], 2 ) ) \n",
    "      \n",
    "    print( \"Real values      \", Y_test[:3] )\n",
    "      \n",
    "    print( \"Trained W        \", round( model.W[0], 2 ) )\n",
    "      \n",
    "    print( \"Trained b        \", round( model.b, 2 ) )\n",
    "      \n",
    "    # Visualization on test set \n",
    "      \n",
    "    plt.scatter( X_test, Y_test, color = 'blue' )\n",
    "      \n",
    "    plt.plot( X_test, Y_pred, color = 'orange' )\n",
    "      \n",
    "    plt.title( 'Salary vs Experience' )\n",
    "      \n",
    "    plt.xlabel( 'Years of Experience' )\n",
    "      \n",
    "    plt.ylabel( 'Salary' )\n",
    "      \n",
    "    plt.show()\n",
    "     \n",
    "if __name__ == \"__main__\" : \n",
    "      \n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fantastic-radar",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-convergence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings( \"ignore\" )\n",
    "  \n",
    "# to compare our model's accuracy with sklearn model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Logistic Regression\n",
    "class LogitRegression() :\n",
    "    def __init__( self, learning_rate, iterations ) :        \n",
    "        self.learning_rate = learning_rate        \n",
    "        self.iterations = iterations\n",
    "          \n",
    "    # Function for model training    \n",
    "    def fit( self, X, Y ) :        \n",
    "        # no_of_training_examples, no_of_features        \n",
    "        self.m, self.n = X.shape        \n",
    "        # weight initialization        \n",
    "        self.W = np.zeros( self.n )        \n",
    "        self.b = 0        \n",
    "        self.X = X        \n",
    "        self.Y = Y\n",
    "          \n",
    "        # gradient descent learning\n",
    "                  \n",
    "        for i in range( self.iterations ) :            \n",
    "            self.update_weights()            \n",
    "        return self\n",
    "      \n",
    "    # Helper function to update weights in gradient descent\n",
    "      \n",
    "    def update_weights( self ) :           \n",
    "        A = 1 / ( 1 + np.exp( - ( self.X.dot( self.W ) + self.b ) ) )\n",
    "          \n",
    "        # calculate gradients        \n",
    "        tmp = ( A - self.Y.T )        \n",
    "        tmp = np.reshape( tmp, self.m )        \n",
    "        dW = np.dot( self.X.T, tmp ) / self.m         \n",
    "        db = np.sum( tmp ) / self.m \n",
    "          \n",
    "        # update weights    \n",
    "        self.W = self.W - self.learning_rate * dW    \n",
    "        self.b = self.b - self.learning_rate * db\n",
    "          \n",
    "        return self\n",
    "      \n",
    "    # Hypothetical function  h( x ) \n",
    "      \n",
    "    def predict( self, X ) :    \n",
    "        Z = 1 / ( 1 + np.exp( - ( X.dot( self.W ) + self.b ) ) )        \n",
    "        Y = np.where( Z > 0.5, 1, 0 )        \n",
    "        return Y\n",
    "  \n",
    "  \n",
    "# Driver code\n",
    "  \n",
    "def main() :\n",
    "      \n",
    "    # Importing dataset    \n",
    "    df = pd.read_csv( \"diabetes.csv\" )\n",
    "    X = df.iloc[:,:-1].values\n",
    "    Y = df.iloc[:,-1:].values\n",
    "      \n",
    "    # Splitting dataset into train and test set\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "      X, Y, test_size = 1/3, random_state = 0 )\n",
    "      \n",
    "    # Model training    \n",
    "    model = LogitRegression( learning_rate = 0.01, iterations = 1000 )\n",
    "      \n",
    "    model.fit( X_train, Y_train )    \n",
    "    model1 = LogisticRegression()    \n",
    "    model1.fit( X_train, Y_train)\n",
    "      \n",
    "    # Prediction on test set\n",
    "    Y_pred = model.predict( X_test )    \n",
    "    Y_pred1 = model1.predict( X_test )\n",
    "      \n",
    "    # measure performance    \n",
    "    correctly_classified = 0    \n",
    "    correctly_classified1 = 0\n",
    "      \n",
    "    # counter    \n",
    "    count = 0    \n",
    "    for count in range( np.size( Y_pred ) ) :  \n",
    "        \n",
    "        if Y_test[count] == Y_pred[count] :            \n",
    "            correctly_classified = correctly_classified + 1\n",
    "          \n",
    "        if Y_test[count] == Y_pred1[count] :            \n",
    "            correctly_classified1 = correctly_classified1 + 1\n",
    "              \n",
    "        count = count + 1\n",
    "          \n",
    "    print( \"Accuracy on test set by our model       :  \", ( \n",
    "      correctly_classified / count ) * 100 )\n",
    "    print( \"Accuracy on test set by sklearn model   :  \", ( \n",
    "      correctly_classified1 / count ) * 100 )\n",
    "  \n",
    "  \n",
    "if __name__ == \"__main__\" :     \n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
